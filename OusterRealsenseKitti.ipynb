{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found successfully\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Takes raw exports from Realsense export tool and Cepton pcap conversion tool\n",
    "Renames files and matches them based on timestamp. Does not modify source directory\n",
    "Inputs:\n",
    "    <date>/\n",
    "        <camerafile>.bag\n",
    "        <lidarfile>.pcap\n",
    "        <lidarfile>.json\n",
    "        <gpsfile>.ubx\n",
    "            \n",
    "Outputs:\n",
    "    Export/\n",
    "        image_00/\n",
    "            Data/\n",
    "                0000000001.png\n",
    "                ...\n",
    "            timestamps.txt\n",
    "        pointcloud/\n",
    "            Data/\n",
    "                0000000001.bin\n",
    "                ...\n",
    "            timestamps.txt\n",
    "\n",
    "Calibration and GPS data are currently handled separately\n",
    "\n",
    "Command to start PTP timestamping on interface enp118s0 (Eth0)\n",
    "sudo ptp4l -S -i enp118s0 -m\n",
    "\"\"\"\n",
    "\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import open3d as o3d\n",
    "from enum import Enum\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pyubx2 import ERR_IGNORE, GET, POLL, SET, UBXReader, UBX_PROTOCOL, NMEA_PROTOCOL, RTCM3_PROTOCOL\n",
    "from ouster.sdk import open_source\n",
    "from ouster.sdk import client\n",
    "from tkinter import *\n",
    "from tkinter.filedialog import askdirectory\n",
    "\n",
    "class FileTypes(Enum):\n",
    "    PCD = 0\n",
    "    BIN = 1\n",
    "    \n",
    "OUTPUT_TYPE = FileTypes.PCD\n",
    "\n",
    "# TODO:\n",
    "# Add cell for conversion of camera .bag to frames\n",
    "\n",
    "# Promt user for raw data directory\n",
    "rawdatapath = askdirectory(title='Select raw data directory')\n",
    "dirfiles = listdir(rawdatapath)\n",
    "path = f\"{rawdatapath}/\"\n",
    "\n",
    "# Parse date and paths\n",
    "parts = rawdatapath.split('/')\n",
    "date = parts[-1]\n",
    "cam_frame_path = path + \"Camera/\"\n",
    "\n",
    "# Required files\n",
    "lidar_pcap = ''\n",
    "lidar_json = ''\n",
    "gps_file = ''\n",
    "cam_bag = ''\n",
    "imu_file = ''\n",
    "\n",
    "# Find required files\n",
    "for file in dirfiles:\n",
    "    if(file.endswith('.pcap')):\n",
    "       lidar_pcap = path + file\n",
    "    elif(file.endswith('.json')):\n",
    "        lidar_json = path + file\n",
    "    elif(file.endswith('.ubx') or file.endswith('.log')):\n",
    "        gps_file = path + file\n",
    "    elif(file.endswith('.bag')):\n",
    "        cam_bag = path + file\n",
    "\n",
    "# Error checking for required data\n",
    "if(lidar_pcap == ''):\n",
    "    raise Exception('ERROR: Lidar pcap not found!')\n",
    "if(lidar_json == ''):\n",
    "    raise Exception('ERROR: Lidar json not found!')\n",
    "if(gps_file == ''):\n",
    "    #raise Exception('ERROR: GPS file not found!')\n",
    "    pass\n",
    "if(os.path.exists(cam_frame_path) == False and cam_bag == ''):\n",
    "    raise Exception('No camera data found!')\n",
    "\n",
    "# Destination paths\n",
    "dest_path = path + \"Export/\"\n",
    "cam_dest = dest_path + 'image_00/'\n",
    "lidar_dest = dest_path + 'pointcloud/'\n",
    "gps_dest = dest_path + 'navigation/'\n",
    "\n",
    "imu_file = ''\n",
    "\n",
    "#Use realsense sdk to convert .bag to frames if none exist yet\n",
    "if(os.path.exists(cam_frame_path) == False):\n",
    "    print('Camera frames not found, converting from bag...')\n",
    "    os.mkdir(cam_frame_path)\n",
    "    os.system(f'rs-convert -i {cam_bag} -p {cam_frame_path}')\n",
    "    print('Exporting IMU data...')\n",
    "    os.system(f'rs-convert -i {cam_bag} -v {cam_frame_path}')\n",
    "\n",
    "# Reference to all files in the camera folder\n",
    "cam_files = [f for f in listdir(cam_frame_path) if isfile(join(cam_frame_path, f))]\n",
    "cam_files.sort()\n",
    "\n",
    "# Find IMU data\n",
    "for file_name in cam_files:\n",
    "    if('imu_pose' in file_name):\n",
    "        imu_file = file_name\n",
    "        break\n",
    "\n",
    "if(imu_file == ''):\n",
    "    raise Exception(\"Error: IMU Data not found!\")\n",
    "\n",
    "print(\"All files found successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Epoch                      Datetime  \\\n",
      "0  1.725905e+12 2024-09-09 18:07:36.224684814   \n",
      "1  1.725905e+12 2024-09-09 18:07:36.258033936   \n",
      "2  1.725905e+12 2024-09-09 18:07:36.291382080   \n",
      "3  1.725905e+12 2024-09-09 18:07:36.324731201   \n",
      "4  1.725905e+12 2024-09-09 18:07:36.358079346   \n",
      "\n",
      "                                         camera_path  \n",
      "0  /home/khanj/Dev/PerceptionTools/DriveData/2024...  \n",
      "1  /home/khanj/Dev/PerceptionTools/DriveData/2024...  \n",
      "2  /home/khanj/Dev/PerceptionTools/DriveData/2024...  \n",
      "3  /home/khanj/Dev/PerceptionTools/DriveData/2024...  \n",
      "4  /home/khanj/Dev/PerceptionTools/DriveData/2024...  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create dataframe of raw camera frame metadata from frame filename. [Epoch, Datetime, Filepath]\n",
    "\"\"\"\n",
    "\n",
    "# Camera metadata dataframe\n",
    "cam_dataframe = pd.DataFrame()\n",
    "temp_data = []\n",
    "\n",
    "# Iterate through each file in the camera frame files\n",
    "for file_name in cam_files:\n",
    "\n",
    "    # If the file is not metadata\n",
    "    if ('metadata' not in file_name) and ('imu_pose' not in file_name):\n",
    "        # Get epoch from filename\n",
    "        trimmedname = file_name.split('_')\n",
    "        parts = trimmedname[2].split('.')\n",
    "\n",
    "        # Append data to frame\n",
    "        temp_dict = { 'Epoch' : float(parts[0] + '.' + parts[1]), \n",
    "                     'Datetime' : pd.to_datetime(float(parts[0] + '.' + parts[1]),unit='ms'),\n",
    "                     'camera_path' : cam_frame_path + file_name }\n",
    "        \n",
    "        # Append camera frame info to running list\n",
    "        temp_data.append(temp_dict)\n",
    "\n",
    "# Keep list of new camera frames\n",
    "#cam_data['Datetime'] = pd.to_datetime(cam_data['Epoch'])\n",
    "cam_dataframe = pd.DataFrame(temp_data)\n",
    "print(cam_dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading metadata from ['/home/khanj/Dev/PerceptionTools/DriveData/2024-09-09/2024099_1105_OS-2-128_122414001752.json']\n",
      "[2024-09-09 12:35:14.598] [ouster::sensor] [info] parsing non-legacy metadata format\n",
      " [####################] 100.0% indexed\n",
      "finished building index\n",
      "frame count: 2097\n",
      "   lidar_id                     Timestart                       Timeend  \\\n",
      "0       879 1970-01-01 00:00:00.000000000 2024-09-09 18:05:01.052299345   \n",
      "1       880 2024-09-09 18:05:01.052398057 2024-09-09 18:05:01.152359244   \n",
      "2       881 2024-09-09 18:05:01.152453023 2024-09-09 18:05:01.252428948   \n",
      "3       882 2024-09-09 18:05:01.252529521 2024-09-09 18:05:01.352468787   \n",
      "4       883 2024-09-09 18:05:01.352561353 2024-09-09 18:05:01.452436919   \n",
      "\n",
      "                                          lidar_path  \\\n",
      "0  /home/khanj/Dev/PerceptionTools/DriveData/2024...   \n",
      "1  /home/khanj/Dev/PerceptionTools/DriveData/2024...   \n",
      "2  /home/khanj/Dev/PerceptionTools/DriveData/2024...   \n",
      "3  /home/khanj/Dev/PerceptionTools/DriveData/2024...   \n",
      "4  /home/khanj/Dev/PerceptionTools/DriveData/2024...   \n",
      "\n",
      "                       Datetime  \n",
      "0 1997-05-06 21:02:30.526149672  \n",
      "1 2024-09-09 18:05:01.102378650  \n",
      "2 2024-09-09 18:05:01.202440985  \n",
      "3 2024-09-09 18:05:01.302499154  \n",
      "4 2024-09-09 18:05:01.402499136  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Parse metadata from ouster pcap into pandas dataframe\n",
    "1. index frames from pcap file\n",
    "2. record frame time start and end\n",
    "3. destagger point representation\n",
    "4. convert destaggered frame points and reflectivity to binary as float32 types\n",
    "\"\"\"\n",
    "\n",
    "# Empty lists of desired data to be combined later\n",
    "frame_ids = []\n",
    "timestarts = []\n",
    "timeends = []\n",
    "xyzr = []\n",
    "filepaths = []\n",
    "\n",
    "imu_accel = []\n",
    "imu_gyro  = []\n",
    "\n",
    "# Load .pcap and .json files\n",
    "source = open_source(lidar_pcap, meta=[lidar_json], index = True)\n",
    "lidar_metadata = source.metadata\n",
    "print('frame count: ' + str(len(source)))\n",
    "\n",
    "# Create binary data directory if doesnt exist\n",
    "if(os.path.exists(f'{path}pointcloud/') == False):\n",
    "    os.mkdir(f'{path}pointcloud/')\n",
    "if(os.path.exists(f'{path}pointcloud/Data/') == False):\n",
    "    os.mkdir(f'{path}pointcloud/Data/')\n",
    "    print('Saved point cloud not found. Regenerating...')\n",
    "\n",
    "# Get function from factory to project scan data to cartesian coordinates\n",
    "xyzl = client.XYZLut(lidar_metadata)\n",
    "packet_format = client.PacketFormat(lidar_metadata)\n",
    "\n",
    "# Iterate through all lidar scan frames\n",
    "for scan in source:\n",
    "    # If the scan is valid\n",
    "    if scan:\n",
    "        # Grab frame id\n",
    "        frame_ids.append(scan.frame_id)\n",
    "        # Grab time start and end for frame\n",
    "        timestarts.append(scan.timestamp[0])\n",
    "        timeends.append(scan.timestamp[-1]) \n",
    "        \n",
    "        # Project points to cartesian and destagger representation\n",
    "        pos = client.destagger(lidar_metadata,xyzl(scan))\n",
    "\n",
    "        # Destagger reflectivity\n",
    "        ref = client.destagger(lidar_metadata,scan.field(client.ChanField.REFLECTIVITY))\n",
    "\n",
    "        # Reshape reflectivity to match XZY's shape\n",
    "        reflectivity_reshaped = np.expand_dims(ref, axis=2)\n",
    "\n",
    "        # Concatenate XYZ and reflectivity and cast to 32-bit floats\n",
    "        xyzref_array = np.concatenate((pos, reflectivity_reshaped), axis=2).astype(np.float32)\n",
    "        xyzr.append(xyzref_array)\n",
    "\n",
    "        if(OUTPUT_TYPE == FileTypes.BIN):\n",
    "            extension = \"bin\"\n",
    "            \n",
    "        elif(OUTPUT_TYPE == FileTypes.PCD):\n",
    "            extension = \"pcd\"\n",
    "\n",
    "        # Grab filepath of point representation\n",
    "        filepath = f\"{path}pointcloud/Data/{scan.frame_id:010d}.\" + extension    \n",
    "        filepaths.append(filepath)  \n",
    "\n",
    "        # Write frame data to disk if doesn't exist\n",
    "        if(os.path.exists(filepath) == False):\n",
    "\n",
    "            # Output files as binary\n",
    "            if(OUTPUT_TYPE == FileTypes.BIN):\n",
    "                # Get byte representation of XYZR\n",
    "                scanbytes = bytearray(xyzref_array)\n",
    "\n",
    "                # Write byte representation to pointcloud/Data/ directory\n",
    "                file = open(filepath, 'wb')\n",
    "                file.write(scanbytes)    \n",
    "\n",
    "            # Output files as PCD\n",
    "            elif(OUTPUT_TYPE == FileTypes.PCD):\n",
    "                # Reshape array\n",
    "                xyzref_array = xyzref_array.reshape((-1,4))[:,0:3]\n",
    "\n",
    "                # Convert to Open3D point cloud\n",
    "                o3d_pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(xyzref_array))\n",
    "\n",
    "                print(f'writing to: {filepath}')\n",
    "                # Save to whatever format you like\n",
    "                o3d.io.write_point_cloud(filepath, o3d_pcd)\n",
    "\n",
    "            else:\n",
    "                print(f'{scan.frame_id} already exists, skipping...')\n",
    "\n",
    "# Build pandas dataframe of desired lidar scan data\n",
    "lidar_dataframe = pd.DataFrame()\n",
    "lidar_dataframe['lidar_id'] = pd.DataFrame(frame_ids)\n",
    "lidar_dataframe['Timestart'] = pd.DataFrame(timestarts)\n",
    "lidar_dataframe['Timeend'] = pd.DataFrame(timeends)\n",
    "lidar_dataframe['lidar_path'] = pd.DataFrame(filepaths)\n",
    "\n",
    "# Convert time strings to datetime objects\n",
    "lidar_dataframe['Timestart'] = pd.to_datetime(lidar_dataframe['Timestart'],unit=NS)\n",
    "lidar_dataframe['Timeend'] = pd.to_datetime(lidar_dataframe['Timeend'],unit=NS)\n",
    "\n",
    "# Assign scan midpoint as frame epoch   \n",
    "lidar_dataframe['Datetime'] = pd.DataFrame(lidar_dataframe['Timestart'] + ((lidar_dataframe['Timeend']-lidar_dataframe['Timestart'])/2))\n",
    "print(lidar_dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 GET messages parsed\n",
      "\n",
      "\n",
      "\n",
      "0 SET messages parsed\n",
      "\n",
      "\n",
      "\n",
      "0 POLL messages parsed\n",
      "\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [Datetime, Latitude, Longitude, Altitude, Alt Unit]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Parse gps data marge with perception frame data\n",
    "Written for .UBX file generated by u-center for u-blox7 USB GPS\n",
    "\"\"\"\n",
    "# Empty dataframe for gps data\n",
    "gpsframe = pd.DataFrame()\n",
    "\n",
    "# Data lists\n",
    "times = []\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "altitudes = []\n",
    "altunits = []\n",
    "alttimes = []\n",
    "\n",
    "# Parse GPS messages from .ubx file\n",
    "for mode in (GET, SET, POLL):\n",
    "    msgcount = 0\n",
    "    ubr = None\n",
    "    \n",
    "    # Open file as U-Center .ubx file\n",
    "    if(gps_file.endswith('.ubx')):\n",
    "        print(\"Reading gps as U-Center output\")\n",
    "        with open(gps_file, \"rb\") as stream:\n",
    "            # Create reader\n",
    "            ubr = UBXReader(stream, quitonerror=ERR_IGNORE, parsing=True,msgmode=mode)\n",
    "\n",
    "        # Iterate through messages parsed by reader\n",
    "        for _, parsed in ubr:\n",
    "            # If message is valid\n",
    "            if parsed is not None:\n",
    "                msgcount += 1\n",
    "\n",
    "                # Grab latitude & longitude if present\n",
    "                if(hasattr(parsed, 'lat')):\n",
    "                    times.append(pd.to_datetime(date + str(' ' + parsed.time.strftime('%H:%M:%S'))))\n",
    "                    latitudes.append(parsed.lat)\n",
    "                    longitudes.append(parsed.lon)\n",
    "                # Grab altitude if present\n",
    "                if(hasattr(parsed,'alt')):\n",
    "                    altitudes.append(parsed.alt)\n",
    "                    altunits.append(parsed.altUnit)\n",
    "                    alttimes.append(pd.to_datetime(date + str(' ' + parsed.time.strftime('%H:%M:%S'))))\n",
    "            \n",
    "    # Open file as pygpsclient .log file\n",
    "    elif(gps_file.endswith('.log')):\n",
    "        print(\"Reading gps as pygpsclient binary output\")\n",
    "        with open(gps_file, 'rb') as stream:\n",
    "            # Create reader\n",
    "            ubr = UBXReader(stream, quitonerror=ERR_IGNORE, parsing=True, protfilter=UBX_PROTOCOL|NMEA_PROTOCOL|RTCM3_PROTOCOL)\n",
    "\n",
    "            # Iterate through messages parsed by reader\n",
    "            for _, parsed in ubr:\n",
    "                # If message is valid\n",
    "                if parsed is not None:\n",
    "                    msgcount += 1\n",
    "\n",
    "                    # Grab latitude & longitude if present\n",
    "                    if(hasattr(parsed, 'lat')):\n",
    "                        times.append(pd.to_datetime(date + str(' ' + parsed.time.strftime('%H:%M:%S'))))\n",
    "                        latitudes.append(parsed.lat)\n",
    "                        longitudes.append(parsed.lon)\n",
    "                    # Grab altitude if present\n",
    "                    if(hasattr(parsed,'alt')):\n",
    "                        altitudes.append(parsed.alt)\n",
    "                        altunits.append(parsed.altUnit)\n",
    "                        alttimes.append(pd.to_datetime(date + str(' ' + parsed.time.strftime('%H:%M:%S'))))\n",
    "\n",
    "    # Print number of messages parsed\n",
    "    print(f'\\n{msgcount} {(\"GET\",\"SET\",\"POLL\")[mode]} messages parsed\\n\\n')\n",
    "\n",
    "# Build gps dataframe\n",
    "gpsframe['Datetime'] = times\n",
    "gpsframe['Latitude'] = latitudes\n",
    "gpsframe['Longitude'] = longitudes\n",
    "\n",
    "# Build separate altitude dataframe since sampling rates are different\n",
    "altframe = pd.DataFrame()\n",
    "altframe['Altitude'] = altitudes\n",
    "altframe['Alt Unit'] = altunits\n",
    "altframe['Datetime'] = alttimes\n",
    "\n",
    "# Sort data by time\n",
    "gpsframe = gpsframe.sort_values(by='Datetime')\n",
    "altframe = altframe.sort_values(by='Datetime')\n",
    "\n",
    "# Merge GPS and nearest Altitude into GPS dataframe. 0 order hold altitude\n",
    "gpsframe = pd.merge_asof(gpsframe,altframe,on='Datetime',suffixes=('_gps','_alt'))\n",
    "print(gpsframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Stream Type_Accel F#_Accel HW Timestamp (ms)_Accel                Datetime  \\\n",
      "0             Accel     1442                46993958 2024-09-09 18:07:36.254   \n",
      "1             Accel     1443                47003873 2024-09-09 18:07:36.264   \n",
      "2             Accel     1444                47013789 2024-09-09 18:07:36.274   \n",
      "3             Accel     1445                47023704 2024-09-09 18:07:36.284   \n",
      "4             Accel     1446                47033620 2024-09-09 18:07:36.294   \n",
      "\n",
      "  Host Timestamp(ms)_Accel 3DOF_x_Accel 3DOF_y_Accel 3DOF_z_Accel  \\\n",
      "0            1725905256254        0.137        9.248        2.942   \n",
      "1            1725905256264        0.127        9.218        2.932   \n",
      "2            1725905256274        0.127        9.228        2.932   \n",
      "3            1725905256284        0.127        9.248        2.932   \n",
      "4            1725905256294        0.137        9.257        2.932   \n",
      "\n",
      "  Stream Type_Gyro F#_Gyro HW Timestamp (ms)_Gyro Host Timestamp(ms)_Gyro  \\\n",
      "0             Gyro    2840               46993905           1725905256254   \n",
      "1             Gyro    2842               47003924           1725905256264   \n",
      "2             Gyro    2844               47013943           1725905256274   \n",
      "3             Gyro    2846               47023962           1725905256284   \n",
      "4             Gyro    2848               47033981           1725905256294   \n",
      "\n",
      "  3DOF_x_Gyro 3DOF_y_Gyro 3DOF_z_Gyro  \n",
      "0      -0.004       0.002       0.001  \n",
      "1      -0.004      -0.002      -0.001  \n",
      "2      -0.003      -0.003      -0.007  \n",
      "3      -0.002       0.007      -0.001  \n",
      "4      -0.002       0.005      -0.006  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Add IMU data to dataframe\n",
    "\"\"\"\n",
    "\n",
    "#TODO:\n",
    "#1. Change backend timestamp to global timestamp for accurate time delay correction\n",
    "\n",
    "# open IMU file\n",
    "rawimu = open(cam_frame_path + imu_file,'r')\n",
    "\n",
    "# Empty lists for dataframe\n",
    "gyro_data = []\n",
    "accel_data = []\n",
    "\n",
    "# Remove leading empty lines written by realsense tool\n",
    "line = rawimu.readline()\n",
    "line = rawimu.readline()    \n",
    "line = rawimu.readline()\n",
    "\n",
    "# Iterate through gyroscope data\n",
    "while(line != '\\n'):\n",
    "    gyro_data.append(line.replace('\\n','').split(','))\n",
    "    line = rawimu.readline()\n",
    "\n",
    "# Remove leading empty lines\n",
    "line = rawimu.readline()\n",
    "line = rawimu.readline()\n",
    "\n",
    "# Iterate through accelerometer data\n",
    "while(line):\n",
    "    accel_data.append(line.replace('\\n','').split(','))\n",
    "    line = rawimu.readline()\n",
    "\n",
    "# Build pandas dataframe of IMU data\n",
    "gyroframe = pd.DataFrame(gyro_data[1:],columns=gyro_data[0])\n",
    "gyroframe['Backend Timestamp(ms)'] = gyroframe['Backend Timestamp(ms)'].astype(np.int64).apply(lambda x: pd.to_datetime(x,unit='ms'))\n",
    "imuframe = pd.DataFrame(accel_data[1:],columns=accel_data[0])\n",
    "imuframe['Backend Timestamp(ms)'] = imuframe['Backend Timestamp(ms)'].astype(np.int64).apply(lambda x: pd.to_datetime(x,unit='ms'))\n",
    "\n",
    "# Merge by backend timestamp\n",
    "imuframe = pd.merge_asof(imuframe,gyroframe,on='Backend Timestamp(ms)',suffixes=('_Accel','_Gyro'))\n",
    "imuframe = imuframe.rename(columns={'Backend Timestamp(ms)':'Datetime'})\n",
    "print(imuframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cam frames: 1776\n",
      "Lidar frames: 2097\n",
      "Lidar frames with no matching camera: 1554\n",
      "   lidar_id                     Timestart                       Timeend  \\\n",
      "0      2432 2024-09-09 18:07:36.244398204 2024-09-09 18:07:36.344308955   \n",
      "1      2433 2024-09-09 18:07:36.344406742 2024-09-09 18:07:36.444255669   \n",
      "2      2434 2024-09-09 18:07:36.444359567 2024-09-09 18:07:36.544237671   \n",
      "3      2435 2024-09-09 18:07:36.544337552 2024-09-09 18:07:36.644215850   \n",
      "4      2436 2024-09-09 18:07:36.644308163 2024-09-09 18:07:36.744183120   \n",
      "\n",
      "                                          lidar_path  \\\n",
      "0  /home/khanj/Dev/PerceptionTools/DriveData/2024...   \n",
      "1  /home/khanj/Dev/PerceptionTools/DriveData/2024...   \n",
      "2  /home/khanj/Dev/PerceptionTools/DriveData/2024...   \n",
      "3  /home/khanj/Dev/PerceptionTools/DriveData/2024...   \n",
      "4  /home/khanj/Dev/PerceptionTools/DriveData/2024...   \n",
      "\n",
      "                       Datetime         Epoch  \\\n",
      "0 2024-09-09 18:07:36.294353579  1.725905e+12   \n",
      "1 2024-09-09 18:07:36.394331205  1.725905e+12   \n",
      "2 2024-09-09 18:07:36.494298619  1.725905e+12   \n",
      "3 2024-09-09 18:07:36.594276701  1.725905e+12   \n",
      "4 2024-09-09 18:07:36.694245641  1.725905e+12   \n",
      "\n",
      "                                         camera_path Stream Type_Accel  \\\n",
      "0  /home/khanj/Dev/PerceptionTools/DriveData/2024...             Accel   \n",
      "1  /home/khanj/Dev/PerceptionTools/DriveData/2024...             Accel   \n",
      "2  /home/khanj/Dev/PerceptionTools/DriveData/2024...             Accel   \n",
      "3  /home/khanj/Dev/PerceptionTools/DriveData/2024...             Accel   \n",
      "4  /home/khanj/Dev/PerceptionTools/DriveData/2024...             Accel   \n",
      "\n",
      "  F#_Accel HW Timestamp (ms)_Accel  ... 3DOF_x_Accel 3DOF_y_Accel  \\\n",
      "0     1446                47033620  ...        0.137        9.257   \n",
      "1     1456                47132782  ...        0.127        9.257   \n",
      "2     1466                47231947  ...        0.127        9.238   \n",
      "3     1476                47331110  ...        0.118        9.228   \n",
      "4     1486                47430275  ...        0.118        9.228   \n",
      "\n",
      "  3DOF_z_Accel Stream Type_Gyro F#_Gyro HW Timestamp (ms)_Gyro  \\\n",
      "0        2.932             Gyro    2848               47033981   \n",
      "1        2.942             Gyro    2867               47129161   \n",
      "2        2.932             Gyro    2887               47229350   \n",
      "3        2.932             Gyro    2907               47329539   \n",
      "4        2.932             Gyro    2927               47429729   \n",
      "\n",
      "  Host Timestamp(ms)_Gyro 3DOF_x_Gyro 3DOF_y_Gyro 3DOF_z_Gyro  \n",
      "0           1725905256294      -0.002       0.005      -0.006  \n",
      "1           1725905256390       0.001       0.000       0.002  \n",
      "2           1725905256490      -0.009       0.001      -0.005  \n",
      "3           1725905256590      -0.002       0.001       0.000  \n",
      "4           1725905256690      -0.005      -0.002      -0.002  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "find closest camera frame for each lidar frame and merge to single dataframe\n",
    "Add GPS data\n",
    "Add IMU data\n",
    "\"\"\"\n",
    "\n",
    "# Print number of frames to be combined\n",
    "print(\"Cam frames: \" + str(len(cam_dataframe.index)))\n",
    "print(\"Lidar frames: \" + str(len(lidar_dataframe.index)))\n",
    "\n",
    "# Left hand SQL style join on lidar and camera frames\n",
    "frame_data = pd.DataFrame()\n",
    "frame_data = pd.merge_asof(lidar_dataframe.sort_values('Datetime'),cam_dataframe.sort_values('Datetime'),on='Datetime')\n",
    "\n",
    "# Print lone lidar frames\n",
    "print(\"Lidar frames with no matching camera: \" + str(frame_data.index.size - frame_data.dropna().index.size))\n",
    "frame_data = frame_data.dropna().reset_index(drop=True)\n",
    "\n",
    "# Calculate time between camera and lidar timestamps\n",
    "#frame_data['fused_frame_deltas'] = (frame_data['Datetime'] - frame_data['Datetime_y']).dt.total_seconds()\n",
    "# Match with closest gps\n",
    "#frame_data = pd.merge_asof(frame_data,gpsframe,on='Datetime')\n",
    "# Match with closest IMU\n",
    "frame_data = pd.merge_asof(frame_data,imuframe,on='Datetime')\n",
    "\n",
    "# Save final dataframe to csv\n",
    "frame_data.to_csv(f'framedata_{date}.csv')\n",
    "print(frame_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/khanj/Dev/PerceptionTools/DriveData/2024-09-09/Export/pointcloud/timestamps.txt'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Move camera and lidar to final dataset directory and rename based on index\n",
    "\"\"\"\n",
    "\n",
    "# Create export directory if does not exist\n",
    "if (not os.path.exists(dest_path)):\n",
    "    os.makedirs(dest_path)\n",
    "if (not os.path.exists(lidar_dest)):\n",
    "    os.makedirs(lidar_dest)\n",
    "    os.makedirs(lidar_dest + 'data/')\n",
    "if (not os.path.exists(cam_dest)):\n",
    "    os.makedirs(cam_dest)\n",
    "    os.makedirs(cam_dest + 'data/')\n",
    "if (not os.path.exists(gps_dest)):\n",
    "    os.makedirs(gps_dest)\n",
    "if (not os.path.exists(gps_dest + 'data/')):\n",
    "    os.makedirs(gps_dest + 'data/')\n",
    "\n",
    "# Write frame timestamps to pointcloud/Data/\n",
    "timepath = f'{path}pointcloud/timestamps_start.txt'\n",
    "if(os.path.exists(timepath) == False):\n",
    "    with open(timepath, 'a') as f:\n",
    "        f.write(lidar_dataframe['Timestart'].to_string(header=False, index=False))\n",
    "\n",
    "timepath = f'{path}pointcloud/timestamps_end.txt'\n",
    "if(os.path.exists(timepath) == False):\n",
    "    with open(timepath, 'a') as f:\n",
    "        f.write(lidar_dataframe['Timeend'].to_string(header=False, index=False))\n",
    "\n",
    "timepath = f'{path}pointcloud/timestamps.txt'\n",
    "if(os.path.exists(timepath) == False):\n",
    "    with open(timepath,'a') as f:\n",
    "        f.write(lidar_dataframe['Datetime'].to_string(header=False, index=False))\n",
    "lidar_dataframe.head()\n",
    "\n",
    "# Move matching frames to dataset directory based on index in matched dataframe\n",
    "for index, row in frame_data.iterrows():    \n",
    "    shutil.copy(row['lidar_path'], lidar_dest + 'data/' + '{index:010d}'.format(index = index) + '.pcd')\n",
    "    shutil.copy(row['camera_path'], cam_dest + 'data/' + '{index:010d}'.format(index = index) + '.png')\n",
    "    #gpspath = gps_dest + 'data/' + f'{index:010d}'.format(index = index) + '.txt'\n",
    "    #f = open(gpspath,'x')\n",
    "    #f.write(str(row['Latitude']) + ' ' + str(row['Longitude']))\n",
    "    #f.close()\n",
    "\n",
    "# Copy lidar timestamps to export\n",
    "shutil.copy(f'{path}pointcloud/timestamps_end.txt', lidar_dest)\n",
    "shutil.copy(f'{path}pointcloud/timestamps_start.txt', lidar_dest)\n",
    "shutil.copy(f'{path}pointcloud/timestamps.txt', lidar_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Move IMU and GPS data to dataset directory\n",
    "'''\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

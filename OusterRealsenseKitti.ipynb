{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Takes raw exports from Realsense export tool and Cepton pcap conversion tool\n",
    "Renames files and matches them based on timestamp. Does not modify source directory\n",
    "Inputs:\n",
    "    <date>/\n",
    "        <camerafile>.bag\n",
    "        <lidarfile>.pcap\n",
    "        <lidarfile>.json\n",
    "        <gpsfile>.ubx\n",
    "            \n",
    "Outputs:\n",
    "    Export/\n",
    "        image_00/\n",
    "            Data/\n",
    "                0000000001.png\n",
    "                ...\n",
    "            timestamps.txt\n",
    "        pointcloud/\n",
    "            Data/\n",
    "                0000000001.bin\n",
    "                ...\n",
    "            timestamps.txt\n",
    "\n",
    "Calibration and GPS data are currently handled separately\n",
    "\n",
    "Command to start PTP timestamping on interface enp118s0 (Eth0)\n",
    "sudo ptp4l -S -i enp118s0 -m\n",
    "\"\"\"\n",
    "\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pyubx2 import ERR_IGNORE, GET, POLL, SET, UBXReader, UBX_PROTOCOL, NMEA_PROTOCOL, RTCM3_PROTOCOL\n",
    "from ouster.sdk import open_source\n",
    "from ouster.sdk import client\n",
    "from tkinter import *\n",
    "from tkinter.filedialog import askdirectory\n",
    "\n",
    "# TODO:\n",
    "# Add cell for conversion of camera .bag to frames\n",
    "\n",
    "# Promt user for raw data directory\n",
    "rawdatapath = askdirectory(title='Select raw data directory')\n",
    "dirfiles = listdir(rawdatapath)\n",
    "path = f\"{rawdatapath}/\"\n",
    "\n",
    "# Parse date and paths\n",
    "parts = rawdatapath.split('/')\n",
    "date = parts[-1]\n",
    "cam_frame_path = path + \"Camera/\"\n",
    "\n",
    "# Required files\n",
    "lidar_pcap = ''\n",
    "lidar_json = ''\n",
    "gps_file = ''\n",
    "cam_bag = ''\n",
    "\n",
    "# Find required files\n",
    "for file in dirfiles:\n",
    "    if(file.endswith('.pcap')):\n",
    "       lidar_pcap = path + file\n",
    "    elif(file.endswith('.json')):\n",
    "        lidar_json = path + file\n",
    "    elif(file.endswith('.ubx') or file.endswith('.log')):\n",
    "        gps_file = path + file\n",
    "    elif(file.endswith('.bag')):\n",
    "        cam_bag = path + file\n",
    "\n",
    "# Error checking for required data\n",
    "if(lidar_pcap == ''):\n",
    "    raise Exception('ERROR: Lidar pcap not found!')\n",
    "if(lidar_json == ''):\n",
    "    raise Exception('ERROR: Lidar json not found!')\n",
    "if(gps_file == ''):\n",
    "    raise Exception('ERROR: GPS file not found!')\n",
    "if(os.path.exists(cam_frame_path) == False and cam_bag == ''):\n",
    "    raise Exception('No camera data found!')\n",
    "\n",
    "# Destination paths\n",
    "dest_path = path + \"Export/\"\n",
    "cam_dest = dest_path + 'image_00/'\n",
    "lidar_dest = dest_path + 'pointcloud/'\n",
    "gps_dest = dest_path + 'oxts/'\n",
    "\n",
    "imu_file = path + ''\n",
    "\n",
    "\n",
    "#Use realsense sdk to convert .bag to frames if none exist yet\n",
    "if(os.path.exists(cam_frame_path) == False):\n",
    "    print('Camera frames not found, converting from bag...')\n",
    "    os.mkdir(cam_frame_path)\n",
    "    os.system(f'rs-convert -i {cam_bag} -p {cam_frame_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create dataframe of raw camera frame metadata from frame filename. [Epoch, Datetime, Filepath]\n",
    "\"\"\"\n",
    "\n",
    "# Camera metadata dataframe\n",
    "cam_dataframe = pd.DataFrame()\n",
    "temp_data = []\n",
    "\n",
    "# Grab all files in the camera folder\n",
    "cam_frame_path = [f for f in listdir(cam_frame_path) if isfile(join(cam_frame_path, f))]\n",
    "cam_frame_path.sort()\n",
    "\n",
    "# Iterate through each file in the camera frame files\n",
    "for file_name in cam_frame_path:\n",
    "\n",
    "    # If the file is not metadata\n",
    "    if ('metadata' in  file_name) == False:\n",
    "        # Get epoch from filename\n",
    "        trimmedname = file_name.split('_')\n",
    "        parts = trimmedname[2].split('.')\n",
    "\n",
    "        # Append data to frame\n",
    "        temp_dict = { 'Epoch' : float(parts[0] + '.' + parts[1]), \n",
    "                     'Datetime' : pd.to_datetime(float(parts[0] + '.' + parts[1]),unit='ms'),\n",
    "                     'camera_path' : file_name }\n",
    "        \n",
    "        # Append camera frame info to running list\n",
    "        temp_data.append(temp_dict)\n",
    "\n",
    "# Keep list of new camera frames\n",
    "#cam_data['Datetime'] = pd.to_datetime(cam_data['Epoch'])\n",
    "cam_dataframe = pd.DataFrame(temp_data)\n",
    "cam_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading metadata from ['/home/khanj/Dev/PerceptionDev/DriveData/2024-08-22/20240822_1524_OS-2-128_122414001752.json']\n",
      "[2024-08-23 15:33:58.858] [ouster::sensor] [info] parsing non-legacy metadata format\n",
      " [####################] 99.4% indexed\n",
      "finished building index\n",
      "frame count: 155\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Timestart</th>\n",
       "      <th>Timeend</th>\n",
       "      <th>lidar_path</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>1970-01-01 00:00:00.000000000</td>\n",
       "      <td>2024-08-22 22:24:37.467389991</td>\n",
       "      <td>/home/khanj/Dev/PerceptionDev/DriveData/2024-0...</td>\n",
       "      <td>1997-04-27 23:12:18.733694995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95</td>\n",
       "      <td>2024-08-22 22:24:37.467496817</td>\n",
       "      <td>2024-08-22 22:24:37.567399041</td>\n",
       "      <td>/home/khanj/Dev/PerceptionDev/DriveData/2024-0...</td>\n",
       "      <td>2024-08-22 22:24:37.517447929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96</td>\n",
       "      <td>2024-08-22 22:24:37.567505011</td>\n",
       "      <td>2024-08-22 22:24:37.667381295</td>\n",
       "      <td>/home/khanj/Dev/PerceptionDev/DriveData/2024-0...</td>\n",
       "      <td>2024-08-22 22:24:37.617443153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97</td>\n",
       "      <td>2024-08-22 22:24:37.667485164</td>\n",
       "      <td>2024-08-22 22:24:37.767339839</td>\n",
       "      <td>/home/khanj/Dev/PerceptionDev/DriveData/2024-0...</td>\n",
       "      <td>2024-08-22 22:24:37.717412501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98</td>\n",
       "      <td>2024-08-22 22:24:37.767428921</td>\n",
       "      <td>2024-08-22 22:24:37.867275940</td>\n",
       "      <td>/home/khanj/Dev/PerceptionDev/DriveData/2024-0...</td>\n",
       "      <td>2024-08-22 22:24:37.817352430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                     Timestart                       Timeend  \\\n",
       "0     94 1970-01-01 00:00:00.000000000 2024-08-22 22:24:37.467389991   \n",
       "1     95 2024-08-22 22:24:37.467496817 2024-08-22 22:24:37.567399041   \n",
       "2     96 2024-08-22 22:24:37.567505011 2024-08-22 22:24:37.667381295   \n",
       "3     97 2024-08-22 22:24:37.667485164 2024-08-22 22:24:37.767339839   \n",
       "4     98 2024-08-22 22:24:37.767428921 2024-08-22 22:24:37.867275940   \n",
       "\n",
       "                                          lidar_path  \\\n",
       "0  /home/khanj/Dev/PerceptionDev/DriveData/2024-0...   \n",
       "1  /home/khanj/Dev/PerceptionDev/DriveData/2024-0...   \n",
       "2  /home/khanj/Dev/PerceptionDev/DriveData/2024-0...   \n",
       "3  /home/khanj/Dev/PerceptionDev/DriveData/2024-0...   \n",
       "4  /home/khanj/Dev/PerceptionDev/DriveData/2024-0...   \n",
       "\n",
       "                       Datetime  \n",
       "0 1997-04-27 23:12:18.733694995  \n",
       "1 2024-08-22 22:24:37.517447929  \n",
       "2 2024-08-22 22:24:37.617443153  \n",
       "3 2024-08-22 22:24:37.717412501  \n",
       "4 2024-08-22 22:24:37.817352430  "
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Parse metadata from ouster pcap into pandas dataframe\n",
    "1. index frames from pcap file\n",
    "2. record frame time start and end\n",
    "3. destagger point representation\n",
    "4. convert destaggered frame points and reflectivity to binary as float32 types\n",
    "\"\"\"\n",
    "\n",
    "# Empty lists of desired data to be combined later\n",
    "frame_ids = []\n",
    "timestarts = []\n",
    "timeends = []\n",
    "xyzr = []\n",
    "filepaths = []\n",
    "\n",
    "imu_accel = []\n",
    "imu_gyro  = []\n",
    "\n",
    "# Load .pcap and .json files\n",
    "source = open_source(lidar_pcap, meta=[lidar_json], index = True)\n",
    "lidar_metadata = source.metadata\n",
    "print('frame count: ' + str(len(source)))\n",
    "\n",
    "# Create binary data directory if doesnt exist\n",
    "if(os.path.exists(f'{path}pointcloud/') == False):\n",
    "    os.mkdir(f'{path}pointcloud/')\n",
    "if(os.path.exists(f'{path}pointcloud/Data/') == False):\n",
    "    os.mkdir(f'{path}pointcloud/Data/')\n",
    "    print('Binary representation not found. Regenerating...')\n",
    "\n",
    "# Get function from factory to project scan data to cartesian coordinates\n",
    "xyzl = client.XYZLut(lidar_metadata)\n",
    "packet_format = client.PacketFormat(lidar_metadata)\n",
    "\n",
    "# Iterate through all lidar scan frames\n",
    "for scan in source:\n",
    "    # If the scan is valid\n",
    "    if scan:\n",
    "        # Grab frame id\n",
    "        frame_ids.append(scan.frame_id)\n",
    "        # Grab time start and end for frame\n",
    "        timestarts.append(scan.timestamp[0])\n",
    "        timeends.append(scan.timestamp[-1])\n",
    "        # Grab filepath of binary representation\n",
    "        filepath = f\"{path}pointcloud/Data/{scan.frame_id:010d}.bin\"    \n",
    "        filepaths.append(filepath)   \n",
    "        \n",
    "        # Project points to cartesian and destagger representation\n",
    "        pos = client.destagger(lidar_metadata,xyzl(scan))\n",
    "\n",
    "        # Destagger reflectivity\n",
    "        ref = client.destagger(lidar_metadata,scan.field(client.ChanField.REFLECTIVITY))\n",
    "\n",
    "        # Reshape reflectivity to match XZY's shape\n",
    "        reflectivity_reshaped = np.expand_dims(ref, axis=2)\n",
    "\n",
    "        # Concatenate XYZ and reflectivity and cast to 32-bit floats\n",
    "        Concatenated_array = np.concatenate((pos, reflectivity_reshaped), axis=2).astype(np.float32)\n",
    "        xyzr.append(Concatenated_array)\n",
    "\n",
    "        # Write binary representation if doesn't exist on disk\n",
    "        if(os.path.exists(filepath) == False):\n",
    "            # Get byte representation of XYZR\n",
    "            scanbytes = bytearray(Concatenated_array)\n",
    "\n",
    "            # Write byte representation to pointcloud/Data/ directory\n",
    "            file = open(filepath, 'wb')\n",
    "            file.write(scanbytes)            \n",
    "\n",
    "# Build pandas dataframe of desired lidar scan data\n",
    "lidar_dataframe = pd.DataFrame()\n",
    "lidar_dataframe['lidar_id'] = pd.DataFrame(frame_ids)\n",
    "lidar_dataframe['Timestart'] = pd.DataFrame(timestarts)\n",
    "lidar_dataframe['Timeend'] = pd.DataFrame(timeends)\n",
    "lidar_dataframe['lidar_path'] = pd.DataFrame(filepaths)\n",
    "\n",
    "# Convert time strings to datetime objects\n",
    "lidar_dataframe['Timestart'] = pd.to_datetime(lidar_dataframe['Timestart'],unit=NS)\n",
    "lidar_dataframe['Timeend'] = pd.to_datetime(lidar_dataframe['Timeend'],unit=NS)\n",
    "\n",
    "# Assign scan midpoint as frame epoch   \n",
    "lidar_dataframe['Datetime'] = pd.DataFrame(lidar_dataframe['Timestart'] + ((lidar_dataframe['Timeend']-lidar_dataframe['Timestart'])/2))\n",
    "\n",
    "# Write frame timestamps to pointcloud/Data/\n",
    "timepath = f'{path}pointcloud/timestamps_start.txt'\n",
    "if(os.path.exists(timepath) == False):\n",
    "    with open(timepath, 'a') as f:\n",
    "        f.write(lidar_dataframe['Timestart'].to_string(header=False, index=False))\n",
    "\n",
    "timepath = f'{path}pointcloud/timestamps_end.txt'\n",
    "if(os.path.exists(timepath) == False):\n",
    "    with open(timepath, 'a') as f:\n",
    "        f.write(lidar_dataframe['Timeend'].to_string(header=False, index=False))\n",
    "\n",
    "timepath = f'{path}pointcloud/timestamps.txt'\n",
    "if(os.path.exists(timepath) == False):\n",
    "    with open(timepath,'a') as f:\n",
    "        f.write(lidar_dataframe['Datetime'].to_string(header=False, index=False))\n",
    "lidar_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading gps as pygpsclient binary output\n",
      "\n",
      "692 GET messages parsed\n",
      "\n",
      "\n",
      "Reading gps as pygpsclient binary output\n",
      "\n",
      "692 SET messages parsed\n",
      "\n",
      "\n",
      "Reading gps as pygpsclient binary output\n",
      "\n",
      "692 POLL messages parsed\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Alt Unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-08-22 21:13:26</td>\n",
       "      <td>48.465164</td>\n",
       "      <td>-122.440104</td>\n",
       "      <td>43.9</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-08-22 21:13:26</td>\n",
       "      <td>48.465164</td>\n",
       "      <td>-122.440104</td>\n",
       "      <td>43.9</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-08-22 21:13:26</td>\n",
       "      <td>48.465164</td>\n",
       "      <td>-122.440104</td>\n",
       "      <td>43.9</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-08-22 21:13:26</td>\n",
       "      <td>48.465164</td>\n",
       "      <td>-122.440104</td>\n",
       "      <td>43.9</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-08-22 21:13:26</td>\n",
       "      <td>48.465164</td>\n",
       "      <td>-122.440104</td>\n",
       "      <td>43.9</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Datetime   Latitude   Longitude Altitude Alt Unit\n",
       "0 2024-08-22 21:13:26  48.465164 -122.440104     43.9        M\n",
       "1 2024-08-22 21:13:26  48.465164 -122.440104     43.9        M\n",
       "2 2024-08-22 21:13:26  48.465164 -122.440104     43.9        M\n",
       "3 2024-08-22 21:13:26  48.465164 -122.440104     43.9        M\n",
       "4 2024-08-22 21:13:26  48.465164 -122.440104     43.9        M"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Parse gps data marge with perception frame data\n",
    "Written for .UBX file generated by u-center for u-blox7 USB GPS\n",
    "\"\"\"\n",
    "# Empty dataframe for gps data\n",
    "gpsframe = pd.DataFrame()\n",
    "\n",
    "# Data lists\n",
    "times = []\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "altitudes = []\n",
    "altunits = []\n",
    "alttimes = []\n",
    "\n",
    "# Parse GPS messages from .ubx file\n",
    "for mode in (GET, SET, POLL):\n",
    "    msgcount = 0\n",
    "    ubr = None\n",
    "    \n",
    "    # Open file as U-Center .ubx file\n",
    "    if(gps_file.endswith('.ubx')):\n",
    "        print(\"Reading gps as U-Center output\")\n",
    "        with open(gps_file, \"rb\") as stream:\n",
    "            # Create reader\n",
    "            ubr = UBXReader(stream, quitonerror=ERR_IGNORE, parsing=True,msgmode=mode)\n",
    "\n",
    "        # Iterate through messages parsed by reader\n",
    "        for _, parsed in ubr:\n",
    "            # If message is valid\n",
    "            if parsed is not None:\n",
    "                msgcount += 1\n",
    "\n",
    "                # Grab latitude & longitude if present\n",
    "                if(hasattr(parsed, 'lat')):\n",
    "                    times.append(pd.to_datetime(date + str(' ' + parsed.time.strftime('%H:%M:%S'))))\n",
    "                    latitudes.append(parsed.lat)\n",
    "                    longitudes.append(parsed.lon)\n",
    "                # Grab altitude if present\n",
    "                if(hasattr(parsed,'alt')):\n",
    "                    altitudes.append(parsed.alt)\n",
    "                    altunits.append(parsed.altUnit)\n",
    "                    alttimes.append(pd.to_datetime(date + str(' ' + parsed.time.strftime('%H:%M:%S'))))\n",
    "            \n",
    "    # Open file as pygpsclient .log file\n",
    "    elif(gps_file.endswith('.log')):\n",
    "        print(\"Reading gps as pygpsclient binary output\")\n",
    "        with open(gps_file, 'rb') as stream:\n",
    "            # Create reader\n",
    "            ubr = UBXReader(stream, quitonerror=ERR_IGNORE, parsing=True, protfilter=UBX_PROTOCOL|NMEA_PROTOCOL|RTCM3_PROTOCOL)\n",
    "\n",
    "            # Iterate through messages parsed by reader\n",
    "            for _, parsed in ubr:\n",
    "                # If message is valid\n",
    "                if parsed is not None:\n",
    "                    msgcount += 1\n",
    "\n",
    "                    # Grab latitude & longitude if present\n",
    "                    if(hasattr(parsed, 'lat')):\n",
    "                        times.append(pd.to_datetime(date + str(' ' + parsed.time.strftime('%H:%M:%S'))))\n",
    "                        latitudes.append(parsed.lat)\n",
    "                        longitudes.append(parsed.lon)\n",
    "                    # Grab altitude if present\n",
    "                    if(hasattr(parsed,'alt')):\n",
    "                        altitudes.append(parsed.alt)\n",
    "                        altunits.append(parsed.altUnit)\n",
    "                        alttimes.append(pd.to_datetime(date + str(' ' + parsed.time.strftime('%H:%M:%S'))))\n",
    "\n",
    "    # Print number of messages parsed\n",
    "    print(f'\\n{msgcount} {(\"GET\",\"SET\",\"POLL\")[mode]} messages parsed\\n\\n')\n",
    "\n",
    "# Build gps dataframe\n",
    "gpsframe['Datetime'] = times\n",
    "gpsframe['Latitude'] = latitudes\n",
    "gpsframe['Longitude'] = longitudes\n",
    "\n",
    "# Build separate altitude dataframe since sampling rates are different\n",
    "altframe = pd.DataFrame()\n",
    "altframe['Altitude'] = altitudes\n",
    "altframe['Alt Unit'] = altunits\n",
    "altframe['Datetime'] = alttimes\n",
    "\n",
    "# Sort data by time\n",
    "gpsframe = gpsframe.sort_values(by='Datetime')\n",
    "altframe = altframe.sort_values(by='Datetime')\n",
    "\n",
    "# Merge GPS and nearest Altitude into GPS dataframe. 0 order hold altitude\n",
    "gpsframe = pd.merge_asof(gpsframe,altframe,on='Datetime',suffixes=('_gps','_alt'))\n",
    "gpsframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_imu.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[169], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#TODO:\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#1. Change backend timestamp to global timestamp for accurate time delay correction\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# open IMU file\u001b[39;00m\n\u001b[1;32m      9\u001b[0m imu_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_imu.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 10\u001b[0m rawimu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimu_file\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Empty lists for dataframe\u001b[39;00m\n\u001b[1;32m     13\u001b[0m gyro_data \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Dev/PerceptionDev/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_imu.csv'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Add IMU data to dataframe\n",
    "\"\"\"\n",
    "\n",
    "#TODO:\n",
    "#1. Change backend timestamp to global timestamp for accurate time delay correction\n",
    "\n",
    "# open IMU file\n",
    "imu_file = 'test_imu.csv'\n",
    "rawimu = open(imu_file,'r')\n",
    "\n",
    "# Empty lists for dataframe\n",
    "gyro_data = []\n",
    "accel_data = []\n",
    "\n",
    "# Remove leading empty lines written by realsense tool\n",
    "line = rawimu.readline()\n",
    "line = rawimu.readline()    \n",
    "line = rawimu.readline()\n",
    "\n",
    "# Iterate through gyroscope data\n",
    "while(line != '\\n'):\n",
    "    gyro_data.append(line.replace('\\n','').split(','))\n",
    "    line = rawimu.readline()\n",
    "\n",
    "# Remove leading empty lines\n",
    "line = rawimu.readline()\n",
    "line = rawimu.readline()\n",
    "\n",
    "# Iterate through accelerometer data\n",
    "while(line):\n",
    "    accel_data.append(line.replace('\\n','').split(','))\n",
    "    line = rawimu.readline()\n",
    "\n",
    "# Build pandas dataframe of IMU data\n",
    "gyroframe = pd.DataFrame(gyro_data[1:],columns=gyro_data[0])\n",
    "gyroframe['Backend Timestamp(ms)'] = gyroframe['Backend Timestamp(ms)'].astype(np.int64).apply(lambda x: pd.to_datetime(x,unit='ms'))\n",
    "imuframe = pd.DataFrame(accel_data[1:],columns=accel_data[0])\n",
    "imuframe['Backend Timestamp(ms)'] = imuframe['Backend Timestamp(ms)'].astype(np.int64).apply(lambda x: pd.to_datetime(x,unit='ms'))\n",
    "\n",
    "# Merge by backend timestamp\n",
    "imuframe = pd.merge_asof(imuframe,gyroframe,on='Backend Timestamp(ms)',suffixes=('_Accel','_Gyro'))\n",
    "imuframe = imuframe.rename(columns={'Backend Timestamp(ms)':'Datetime'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cam frames: 8121\n",
      "Lidar frames: 5285\n"
     ]
    },
    {
     "ename": "MergeError",
     "evalue": "incompatible merge keys [0] dtype('uint64') and dtype('float64'), must be the same type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Left hand SQL style join on lidar and camera frames\u001b[39;00m\n\u001b[1;32m     15\u001b[0m frame_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m---> 16\u001b[0m frame_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_asof\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlidar_dataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcam_dataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEpoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEpoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Print lone lidar frames\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLidar frames with no matching camera: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(frame_data\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m-\u001b[39m frame_data\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39msize))\n",
      "File \u001b[0;32m~/Dev/PerceptionDev/.venv/lib/python3.10/site-packages/pandas/core/reshape/merge.py:691\u001b[0m, in \u001b[0;36mmerge_asof\u001b[0;34m(left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, suffixes, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_asof\u001b[39m(\n\u001b[1;32m    441\u001b[0m     left: DataFrame \u001b[38;5;241m|\u001b[39m Series,\n\u001b[1;32m    442\u001b[0m     right: DataFrame \u001b[38;5;241m|\u001b[39m Series,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    454\u001b[0m     direction: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    455\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m    456\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03m    Perform a merge by key distance.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;124;03m    4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 691\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_AsOfMerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_by\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_by\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_by\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masof\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_exact_matches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_exact_matches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/Dev/PerceptionDev/.venv/lib/python3.10/site-packages/pandas/core/reshape/merge.py:1999\u001b[0m, in \u001b[0;36m_AsOfMerge.__init__\u001b[0;34m(self, left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, suffixes, how, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1994\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_exact_matches must be boolean, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1995\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallow_exact_matches\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1996\u001b[0m     )\n\u001b[1;32m   1997\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(msg)\n\u001b[0;32m-> 1999\u001b[0m \u001b[43m_OrderedMerge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2000\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2003\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2004\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2007\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2008\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2009\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2010\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2011\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/PerceptionDev/.venv/lib/python3.10/site-packages/pandas/core/reshape/merge.py:1911\u001b[0m, in \u001b[0;36m_OrderedMerge.__init__\u001b[0;34m(self, left, right, on, left_on, right_on, left_index, right_index, suffixes, fill_method, how)\u001b[0m\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m   1898\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1899\u001b[0m     left: DataFrame \u001b[38;5;241m|\u001b[39m Series,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1908\u001b[0m     how: JoinHow \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masof\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1909\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1910\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_method \u001b[38;5;241m=\u001b[39m fill_method\n\u001b[0;32m-> 1911\u001b[0m     \u001b[43m_MergeOperation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1912\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1913\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# factorize sorts\u001b[39;49;00m\n\u001b[1;32m   1923\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dev/PerceptionDev/.venv/lib/python3.10/site-packages/pandas/core/reshape/merge.py:802\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m right_drop:\n\u001b[1;32m    800\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright\u001b[38;5;241m.\u001b[39m_drop_labels_or_levels(right_drop)\n\u001b[0;32m--> 802\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_require_matching_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright_join_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tolerance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys)\n\u001b[1;32m    805\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n",
      "File \u001b[0;32m~/Dev/PerceptionDev/.venv/lib/python3.10/site-packages/pandas/core/reshape/merge.py:2124\u001b[0m, in \u001b[0;36m_AsOfMerge._maybe_require_matching_dtypes\u001b[0;34m(self, left_join_keys, right_join_keys)\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;66;03m# validate index types are the same\u001b[39;00m\n\u001b[1;32m   2123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (lk, rk) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(left_join_keys, right_join_keys)):\n\u001b[0;32m-> 2124\u001b[0m     \u001b[43m_check_dtype_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_index:\n\u001b[1;32m   2127\u001b[0m     lt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_values\n",
      "File \u001b[0;32m~/Dev/PerceptionDev/.venv/lib/python3.10/site-packages/pandas/core/reshape/merge.py:2120\u001b[0m, in \u001b[0;36m_AsOfMerge._maybe_require_matching_dtypes.<locals>._check_dtype_match\u001b[0;34m(left, right, i)\u001b[0m\n\u001b[1;32m   2115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2116\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2117\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible merge keys [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(left\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2118\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(right\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, must be the same type\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2119\u001b[0m     )\n\u001b[0;32m-> 2120\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m MergeError(msg)\n",
      "\u001b[0;31mMergeError\u001b[0m: incompatible merge keys [0] dtype('uint64') and dtype('float64'), must be the same type"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "find closest camera frame for each lidar frame and merge to single dataframe\n",
    "Add GPS data\n",
    "Add IMU data\n",
    "\"\"\"\n",
    "\n",
    "# Print number of frames to be combined\n",
    "print(\"Cam frames: \" + str(len(cam_dataframe.index)))\n",
    "print(\"Lidar frames: \" + str(len(lidar_dataframe.index)))\n",
    "\n",
    "# Create lidar time reference point to match camera frames by\n",
    "lidar_dataframe['Epoch'] = lidar_dataframe['Timeend']\n",
    "\n",
    "# Left hand SQL style join on lidar and camera frames\n",
    "frame_data = pd.DataFrame()\n",
    "frame_data = pd.merge_asof(lidar_dataframe,cam_dataframe.sort_values('Epoch'),on='Epoch')\n",
    "\n",
    "# Print lone lidar frames\n",
    "print(\"Lidar frames with no matching camera: \" + str(frame_data.index.size - frame_data.dropna().index.size))\n",
    "frame_data = frame_data.dropna().reset_index(drop=True)\n",
    "frame_data = frame_data.rename(columns={'Datetime_x': 'Datetime'})\n",
    "\n",
    "# Calculate time between camera and lidar timestamps\n",
    "frame_data['fused_frame_deltas'] = (frame_data['Datetime'] - frame_data['Datetime_y']).dt.total_seconds()\n",
    "# Match with closest gps\n",
    "frame_data = pd.merge_asof(frame_data,gpsframe,on='Datetime')\n",
    "# Match with closest IMU\n",
    "print(imuframe)\n",
    "frame_data = pd.merge_asof(frame_data,imuframe,on='Datetime')\n",
    "\n",
    "# Save final dataframe to csv\n",
    "frame_data.to_csv(f'framedata_{date}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Move to final dataset directory and rename based on index in dataset\n",
    "\"\"\"\n",
    "\n",
    "# Create export directory if does not exist\n",
    "if (not os.path.exists(dest_path)):\n",
    "    os.makedirs(dest_path)\n",
    "if (not os.path.exists(lidar_dest)):\n",
    "    os.makedirs(lidar_dest)\n",
    "    os.makedirs(lidar_dest + 'data/')\n",
    "if (not os.path.exists(cam_dest)):\n",
    "    os.makedirs(cam_dest)\n",
    "    os.makedirs(cam_dest + 'data/')\n",
    "if (not os.path.exists(gps_dest)):\n",
    "    os.makedirs(gps_dest)\n",
    "if (not os.path.exists(gps_dest + 'data/')):\n",
    "    os.makedirs(gps_dest + 'data/')\n",
    "\n",
    "# Move matching frames to dataset directory based on index in matched dataframe\n",
    "for index, row in frame_data.iterrows():    \n",
    "    shutil.copy(lidar_origin + row['lidar_path'], lidar_dest + 'data/' + '{index:010d}'.format(index = index) + '.pcd')\n",
    "    shutil.copy(cam_origin + row['camera_path'], cam_dest + 'data/' + '{index:010d}'.format(index = index) + '.png')\n",
    "    gpspath = gps_dest + 'data/' + f'{index:010d}'.format(index = index) + '.txt'\n",
    "    f = open(gpspath,'x')\n",
    "    f.write(str(row['Latitude']) + ' ' + str(row['Longitude']))\n",
    "    f.close()\n",
    "\n",
    "\n",
    "# Create timestamps files for camera\n",
    "cam_times = frame_data['Datetime_y'].to_csv(cam_dest + 'timestamps.txt',index=False,header=False)\n",
    "\n",
    "# Create timestamps files for lidar\n",
    "lidar_times = frame_data['Datetime_x'].to_csv(lidar_dest + 'timestamps.txt',index=False,header=False)\n",
    "\n",
    "# Write GPS timestamps to file\n",
    "gps_times = frame_data['Datetime_x'].to_csv(gps_dest + 'timestamps.txt',index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

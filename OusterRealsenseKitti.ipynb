{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found successfully\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Takes raw exports from Realsense export tool and Cepton pcap conversion tool\n",
    "Renames files and matches them based on timestamp. Does not modify source directory\n",
    "Inputs:\n",
    "    <date>/\n",
    "        <camerafile>.bag\n",
    "        <lidarfile>.pcap\n",
    "        <lidarfile>.json\n",
    "        <gpsfile>.ubx\n",
    "            \n",
    "Outputs:\n",
    "    Export/\n",
    "        image_00/\n",
    "            Data/\n",
    "                0000000001.png\n",
    "                ...\n",
    "            timestamps.txt\n",
    "        pointcloud/\n",
    "            Data/\n",
    "                0000000001.bin\n",
    "                ...\n",
    "            timestamps.txt\n",
    "\n",
    "Calibration and GPS data are currently handled separately\n",
    "\n",
    "Command to start PTP timestamping on interface enp118s0 (Eth0)\n",
    "sudo ptp4l -S -i enp118s0 -m\n",
    "\"\"\"\n",
    "\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import open3d as o3d\n",
    "from enum import Enum\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pyubx2 import ERR_IGNORE, GET, POLL, SET, UBXReader, UBX_PROTOCOL, NMEA_PROTOCOL, RTCM3_PROTOCOL\n",
    "from ouster.sdk import open_source\n",
    "from ouster.sdk import client\n",
    "from ouster.sdk import pcap\n",
    "from tkinter import *\n",
    "from tkinter.filedialog import askdirectory\n",
    "\n",
    "class FileTypes(Enum):\n",
    "    PCD = 0\n",
    "    BIN = 1\n",
    "\n",
    "class IMUTypes(Enum):\n",
    "    REALSENSE_IMU = 0\n",
    "    OUSTER_IMU = 1\n",
    " \n",
    "    \n",
    "#\n",
    "#Options\n",
    "#\n",
    "OUTPUT_TYPE = FileTypes.BIN\n",
    "IMU = IMUTypes.OUSTER_IMU\n",
    "\n",
    "# Promt user for raw data directory\n",
    "rawdatapath = askdirectory(title='Select raw data directory')\n",
    "dirfiles = listdir(rawdatapath)\n",
    "path = f\"{rawdatapath}/\"\n",
    "\n",
    "# Parse date and paths\n",
    "parts = rawdatapath.split('/')\n",
    "date = pd.Timestamp(parts[-1])\n",
    "cam_frame_path = path + \"Camera/\"\n",
    "\n",
    "# Required files\n",
    "lidar_pcap = ''\n",
    "lidar_json = ''\n",
    "gps_file = ''\n",
    "cam_bag = ''\n",
    "imu_file = ''\n",
    "\n",
    "# Find required files\n",
    "for file in dirfiles:\n",
    "    if(file.endswith('.pcap')):\n",
    "       lidar_pcap = path + file\n",
    "    elif(file.endswith('.json')):\n",
    "        lidar_json = path + file\n",
    "    elif(file.endswith('.ubx') or file.endswith('.log')):\n",
    "        gps_file = path + file\n",
    "    elif(file.endswith('.bag')):\n",
    "        cam_bag = path + file\n",
    "\n",
    "# Error checking for required data\n",
    "if(lidar_pcap == ''):\n",
    "    raise Exception('ERROR: Lidar pcap not found!')\n",
    "if(lidar_json == ''):\n",
    "    raise Exception('ERROR: Lidar json not found!')\n",
    "if(gps_file == ''):\n",
    "    #raise Exception('ERROR: GPS file not found!')\n",
    "    pass\n",
    "if(os.path.exists(cam_frame_path) == False and cam_bag == ''):\n",
    "    raise Exception('No camera data found!')\n",
    "\n",
    "# Destination paths\n",
    "dest_path = path + \"Export/\"\n",
    "cam_dest = dest_path + 'image_00/'\n",
    "lidar_dest = dest_path + 'pointcloud/'\n",
    "gps_dest = dest_path + 'navigation/'\n",
    "\n",
    "imu_file = ''\n",
    "\n",
    "#Use realsense sdk to convert .bag to frames if none exist yet\n",
    "if(os.path.exists(cam_frame_path) == False):\n",
    "    print('Camera frames not found, converting from bag...')\n",
    "    os.mkdir(cam_frame_path)\n",
    "    os.system(f'rs-convert -i {cam_bag} -p {cam_frame_path}')\n",
    "    print('Exporting IMU data...')\n",
    "    os.system(f'rs-convert -i {cam_bag} -v {cam_frame_path}')\n",
    "\n",
    "# Reference to all files in the camera folder\n",
    "cam_files = [f for f in listdir(cam_frame_path) if isfile(join(cam_frame_path, f))]\n",
    "cam_files.sort()\n",
    "\n",
    "# Find IMU file\n",
    "for file_name in cam_files:\n",
    "    if('imu_pose' in file_name):\n",
    "        imu_file = file_name\n",
    "        break\n",
    "\n",
    "if (imu_file == ''):\n",
    "    print('Exporting IMU data...')\n",
    "    os.system(f'rs-convert -i {cam_bag} -v {cam_frame_path}')\n",
    "\n",
    "    # Find IMU file\n",
    "    for file_name in cam_files:\n",
    "        if('imu_pose' in file_name):\n",
    "            imu_file = file_name\n",
    "            break\n",
    "\n",
    "if(imu_file == ''):\n",
    "    raise Exception(\"Error: IMU Data not found!\")\n",
    "\n",
    "print(\"All files found successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Epoch                            Datetime  \\\n",
      "0  1.725935e+12 2024-09-09 19:21:43.678851074-07:00   \n",
      "1  1.725935e+12 2024-09-09 19:21:43.712199707-07:00   \n",
      "2  1.725935e+12 2024-09-09 19:21:43.745549316-07:00   \n",
      "3  1.725935e+12 2024-09-09 19:21:43.778897949-07:00   \n",
      "4  1.725935e+12 2024-09-09 19:21:43.812247559-07:00   \n",
      "\n",
      "                                         camera_path  \n",
      "0  /home/khanj/Dev/PerceptionTools/DriveData/2024...  \n",
      "1  /home/khanj/Dev/PerceptionTools/DriveData/2024...  \n",
      "2  /home/khanj/Dev/PerceptionTools/DriveData/2024...  \n",
      "3  /home/khanj/Dev/PerceptionTools/DriveData/2024...  \n",
      "4  /home/khanj/Dev/PerceptionTools/DriveData/2024...  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create dataframe of raw camera frame metadata from frame filename. [Epoch, Datetime, Filepath]\n",
    "\"\"\"\n",
    "\n",
    "# Camera metadata dataframe\n",
    "cam_dataframe = pd.DataFrame()\n",
    "temp_data = []\n",
    "\n",
    "# Iterate through each file in the camera frame files\n",
    "for file_name in cam_files:\n",
    "\n",
    "    # If the file is not metadata\n",
    "    if ('metadata' not in file_name) and ('imu_pose' not in file_name):\n",
    "        # Get epoch from filename\n",
    "        trimmedname = file_name.split('_')\n",
    "        parts = trimmedname[2].split('.')\n",
    "\n",
    "        # Append data to frame\n",
    "        temp_dict = { 'Epoch' : float(parts[0] + '.' + parts[1]), \n",
    "                     'Datetime' : pd.to_datetime(float(parts[0] + '.' + parts[1]),unit='ms'),\n",
    "                     'camera_path' : cam_frame_path + file_name }\n",
    "        \n",
    "        # Append camera frame info to running list\n",
    "        temp_data.append(temp_dict)\n",
    "\n",
    "# Keep list of new camera frames\n",
    "#cam_data['Datetime'] = pd.to_datetime(cam_data['Epoch'])\n",
    "cam_dataframe = pd.DataFrame(temp_data)\n",
    "cam_dataframe['Datetime'] = cam_dataframe['Datetime'].dt.tz_localize('GMT').dt.tz_convert('America/Los_Angeles')\n",
    "print(cam_dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/khanj/Dev/PerceptionTools/DriveData/2024-09-09/2024099_1921_OS-2-128_122414001752.pcap\n",
      "loading metadata from ['/home/khanj/Dev/PerceptionTools/DriveData/2024-09-09/2024099_1921_OS-2-128_122414001752.json']\n",
      "[2024-09-23 10:33:46.649] [ouster::sensor] [info] parsing non-legacy metadata format\n",
      " [####################] 100.0% indexed\n",
      "finished building index\n",
      "frame count: 4527\n",
      "Scanning frames...\n",
      "Building lidar dataframe\n",
      "   lidar_id                           Timestart  \\\n",
      "0      2224           1969-12-31 16:00:00-08:00   \n",
      "1      2225 2024-09-09 19:21:49.466755093-07:00   \n",
      "2      2226 2024-09-09 19:21:49.566716380-07:00   \n",
      "3      2227 2024-09-09 19:21:49.666685136-07:00   \n",
      "4      2228 2024-09-09 19:21:49.766677044-07:00   \n",
      "\n",
      "                              Timeend  \\\n",
      "0 2024-09-09 19:21:49.466666149-07:00   \n",
      "1 2024-09-09 19:21:49.566618911-07:00   \n",
      "2 2024-09-09 19:21:49.666578590-07:00   \n",
      "3 2024-09-09 19:21:49.766573072-07:00   \n",
      "4 2024-09-09 19:21:49.866579745-07:00   \n",
      "\n",
      "                                          lidar_path  \\\n",
      "0  /home/khanj/Dev/PerceptionTools/DriveData/2024...   \n",
      "1  /home/khanj/Dev/PerceptionTools/DriveData/2024...   \n",
      "2  /home/khanj/Dev/PerceptionTools/DriveData/2024...   \n",
      "3  /home/khanj/Dev/PerceptionTools/DriveData/2024...   \n",
      "4  /home/khanj/Dev/PerceptionTools/DriveData/2024...   \n",
      "\n",
      "                             Datetime  \n",
      "0 1997-05-06 18:10:54.733333074-07:00  \n",
      "1 2024-09-09 19:21:49.516687002-07:00  \n",
      "2 2024-09-09 19:21:49.616647485-07:00  \n",
      "3 2024-09-09 19:21:49.716629104-07:00  \n",
      "4 2024-09-09 19:21:49.816628394-07:00  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Parse metadata from ouster pcap into pandas dataframe\n",
    "1. index frames from pcap file\n",
    "2. record frame time start and end\n",
    "3. destagger point representation\n",
    "4. convert destaggered frame points and reflectivity to binary as float32 types\n",
    "\"\"\"\n",
    "\n",
    "# Empty lists of desired data to be combined later\n",
    "frame_ids = []\n",
    "timestarts = []\n",
    "timeends = []\n",
    "xyzr = []\n",
    "filepaths = []\n",
    "\n",
    "imu_accel = []\n",
    "imu_gyro  = []\n",
    "\n",
    "# Load .pcap and .json files\n",
    "print(lidar_pcap)\n",
    "source = open_source(lidar_pcap, meta=[lidar_json], index = True)\n",
    "lidar_metadata = source.metadata\n",
    "print('frame count: ' + str(len(source)))\n",
    "\n",
    "# Create binary data directory if doesnt exist\n",
    "if(os.path.exists(f'{path}pointcloud/') == False):\n",
    "    os.mkdir(f'{path}pointcloud/')\n",
    "if(os.path.exists(f'{path}pointcloud/Data/') == False):\n",
    "    os.mkdir(f'{path}pointcloud/Data/')\n",
    "    print('Saved point cloud not found. Regenerating...')\n",
    "\n",
    "# Get function from factory to project scan data to cartesian coordinates\n",
    "xyzl = client.XYZLut(lidar_metadata)\n",
    "packet_format = client.PacketFormat(lidar_metadata)\n",
    "\n",
    "# Iterate through all lidar scan frames\n",
    "print('Scanning frames...')\n",
    "for scan in source:\n",
    "    # If the scan is valid\n",
    "    if scan:\n",
    "        # Grab frame id\n",
    "        frame_ids.append(scan.frame_id)\n",
    "        # Grab time start and end for frame\n",
    "        timestarts.append(scan.timestamp[0])\n",
    "        timeends.append(scan.timestamp[-1]) \n",
    "        \n",
    "        # Project points to cartesian and destagger representation\n",
    "        pos = client.destagger(lidar_metadata,xyzl(scan))\n",
    "\n",
    "        # Destagger reflectivity\n",
    "        ref = client.destagger(lidar_metadata,scan.field(client.ChanField.REFLECTIVITY))\n",
    "\n",
    "        # Reshape reflectivity to match XZY's shape\n",
    "        reflectivity_reshaped = np.expand_dims(ref, axis=2)\n",
    "\n",
    "        # Concatenate XYZ and reflectivity and cast to 32-bit floats\n",
    "        xyzref_array = np.concatenate((pos, reflectivity_reshaped), axis=2).astype(np.float32)\n",
    "        xyzr.append(xyzref_array)\n",
    "\n",
    "        if(OUTPUT_TYPE == FileTypes.BIN):\n",
    "            extension = \"bin\"\n",
    "            \n",
    "        elif(OUTPUT_TYPE == FileTypes.PCD):\n",
    "            extension = \"pcd\"\n",
    "\n",
    "        # Grab filepath of point representation\n",
    "        filepath = f\"{path}pointcloud/Data/{scan.frame_id:010d}.\" + extension    \n",
    "        filepaths.append(filepath)  \n",
    "\n",
    "        # Write frame data to disk if doesn't exist\n",
    "        if(os.path.exists(filepath) == False):\n",
    "\n",
    "            # Output files as binary\n",
    "            if(OUTPUT_TYPE == FileTypes.BIN):\n",
    "                # Get byte representation of XYZR\n",
    "                scanbytes = bytearray(xyzref_array)\n",
    "\n",
    "                # Write byte representation to pointcloud/Data/ directory\n",
    "                file = open(filepath, 'wb')\n",
    "                file.write(scanbytes)    \n",
    "\n",
    "            # Output files as PCD\n",
    "            elif(OUTPUT_TYPE == FileTypes.PCD):\n",
    "                # Reshape array\n",
    "                xyzref_array = xyzref_array.reshape((-1,4))[:,0:3]\n",
    "\n",
    "                # Convert to Open3D point cloud\n",
    "                o3d_pcd = o3d.geometry.PointCloud(o3d.utility.Vector3dVector(xyzref_array))\n",
    "\n",
    "                print(f'writing to: {filepath}')\n",
    "                # Save to whatever format you like\n",
    "                o3d.io.write_point_cloud(filepath, o3d_pcd)\n",
    "\n",
    "            else:\n",
    "                print(f'{scan.frame_id} already exists, skipping...')\n",
    "\n",
    "print('Building lidar dataframe')\n",
    "# Build pandas dataframe of desired lidar scan data\n",
    "lidar_dataframe = pd.DataFrame()\n",
    "lidar_dataframe['lidar_id'] = pd.DataFrame(frame_ids)\n",
    "lidar_dataframe['Timestart'] = pd.DataFrame(timestarts)\n",
    "lidar_dataframe['Timeend'] = pd.DataFrame(timeends)\n",
    "lidar_dataframe['lidar_path'] = pd.DataFrame(filepaths)\n",
    "\n",
    "lidar_dataframe.to_csv('timetest.csv')\n",
    "\n",
    "# Convert time strings to datetime objects\n",
    "lidar_dataframe['Timestart'] = pd.to_datetime(lidar_dataframe['Timestart'],unit='ns')\n",
    "lidar_dataframe['Timeend'] = pd.to_datetime(lidar_dataframe['Timeend'],unit='ns')\n",
    "\n",
    "# Convert from GMT to PST timezone\n",
    "lidar_dataframe['Timestart'] = lidar_dataframe['Timestart'].dt.tz_localize('GMT').dt.tz_convert('America/Los_Angeles')\n",
    "lidar_dataframe['Timeend'] = lidar_dataframe['Timeend'].dt.tz_localize('GMT').dt.tz_convert('America/Los_Angeles')\n",
    "\n",
    "# Assign scan midpoint as frame epoch   \n",
    "lidar_dataframe['Datetime'] = pd.DataFrame(lidar_dataframe['Timestart'] + ((lidar_dataframe['Timeend']-lidar_dataframe['Timestart'])/2))\n",
    "print(lidar_dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-23 10:34:08.972] [ouster::sensor] [info] parsing non-legacy metadata format\n",
      "                                 Datetime     Acc_x     Acc_y     Acc_z  \\\n",
      "1     2024-09-09 19:21:49.474194285-07:00 -0.013672  0.024414  0.970947   \n",
      "2     2024-09-09 19:21:49.484194224-07:00  0.011963  0.015381  0.975098   \n",
      "3     2024-09-09 19:21:49.494194065-07:00  0.010742  0.009277  0.985840   \n",
      "4     2024-09-09 19:21:49.504193971-07:00 -0.014160  0.018555  0.983887   \n",
      "5     2024-09-09 19:21:49.514193889-07:00 -0.009033  0.016846  0.978760   \n",
      "...                                   ...       ...       ...       ...   \n",
      "45247 2024-09-09 19:29:21.976853423-07:00 -0.007812 -0.020996  0.972900   \n",
      "45248 2024-09-09 19:29:21.986853521-07:00 -0.002441 -0.026367  0.986084   \n",
      "45249 2024-09-09 19:29:21.996853609-07:00 -0.001709 -0.023926  0.978516   \n",
      "45250 2024-09-09 19:29:22.006853703-07:00 -0.010254 -0.015869  0.973877   \n",
      "45251 2024-09-09 19:29:22.016853827-07:00 -0.011230 -0.026367  0.965088   \n",
      "\n",
      "         Gyro_x    Gyro_y    Gyro_z  \n",
      "1      0.144958  0.747681 -0.114441  \n",
      "2      0.152588  0.450134 -0.152588  \n",
      "3      0.518799  0.160217  0.106812  \n",
      "4      0.251770  0.221252 -0.045776  \n",
      "5     -0.228882  0.160217 -0.183105  \n",
      "...         ...       ...       ...  \n",
      "45247  0.762939  0.518799 -0.221252  \n",
      "45248  0.831604  0.175476 -0.183105  \n",
      "45249 -0.076294 -0.610352  0.099182  \n",
      "45250 -0.114441 -0.404358 -0.167847  \n",
      "45251  0.106812  0.106812 -0.137329  \n",
      "\n",
      "[45251 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Read IMU data from Ouster\n",
    "'''\n",
    "\n",
    "acc_times = []\n",
    "accx = []\n",
    "accy = []\n",
    "accz = []\n",
    "\n",
    "gyrotimes = []\n",
    "gyrox = []\n",
    "gyroy = []\n",
    "gyroz = []\n",
    "\n",
    "if(IMU == IMUTypes.OUSTER_IMU):\n",
    "    # Read IMU data\n",
    "    with open(lidar_json, 'r') as f:\n",
    "        metadata = client.SensorInfo(f.read())\n",
    "\n",
    "    source = pcap.Pcap(lidar_pcap, metadata)\n",
    "\n",
    "    packet_format = client.PacketFormat(metadata)\n",
    "    for packet in source:\n",
    "        if isinstance(packet, client.ImuPacket):\n",
    "            # and access ImuPacket content\n",
    "            acc_times.append(packet_format.imu_accel_ts(packet.buf))\n",
    "            accx.append(packet_format.imu_la_x(packet.buf))\n",
    "            accy.append(packet_format.imu_la_y(packet.buf))\n",
    "            accz.append(packet_format.imu_la_z(packet.buf))\n",
    "\n",
    "            gyrotimes.append(packet_format.imu_gyro_ts(packet.buf))\n",
    "            gyrox.append(packet_format.imu_av_x(packet.buf))\n",
    "            gyroy.append(packet_format.imu_av_y(packet.buf))\n",
    "            gyroz.append(packet_format.imu_av_z(packet.buf))\n",
    "\n",
    "    acc_frame = pd.DataFrame()\n",
    "    acc_frame['Datetime'] = pd.to_datetime(acc_times)\n",
    "    acc_frame['Datetime'] = acc_frame['Datetime'].dt.tz_localize('GMT').dt.tz_convert('America/Los_Angeles')\n",
    "    acc_frame['Acc_x'] = accx\n",
    "    acc_frame['Acc_y'] = accy\n",
    "    acc_frame['Acc_z'] = accz\n",
    "\n",
    "    gyro_frame = pd.DataFrame()\n",
    "    gyro_frame['Datetime'] = pd.to_datetime(gyrotimes)\n",
    "    gyro_frame['Datetime'] = gyro_frame['Datetime'].dt.tz_localize('GMT').dt.tz_convert('America/Los_Angeles')\n",
    "    gyro_frame['Gyro_x'] = gyrox\n",
    "    gyro_frame['Gyro_y'] = gyroy\n",
    "    gyro_frame['Gyro_z'] = gyroz\n",
    "\n",
    "    imu_frame = pd.merge_asof(acc_frame,gyro_frame,on='Datetime')\n",
    "    imu_frame = imu_frame.dropna()\n",
    "\n",
    "    print(imu_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading gps as pygpsclient binary output\n",
      "\n",
      "3554 GET messages parsed\n",
      "\n",
      "\n",
      "Reading gps as pygpsclient binary output\n",
      "\n",
      "3554 SET messages parsed\n",
      "\n",
      "\n",
      "Reading gps as pygpsclient binary output\n",
      "\n",
      "3554 POLL messages parsed\n",
      "\n",
      "\n",
      "                     Datetime   Latitude   Longitude  Altitude Alt Unit\n",
      "162 2024-09-09 19:21:32-07:00  48.775236 -122.457057      56.1        M\n",
      "163 2024-09-09 19:21:32-07:00  48.775236 -122.457057      56.1        M\n",
      "164 2024-09-09 19:21:32-07:00  48.775236 -122.457057      56.1        M\n",
      "165 2024-09-09 19:21:32-07:00  48.775236 -122.457057      56.1        M\n",
      "166 2024-09-09 19:21:32-07:00  48.775236 -122.457057      56.1        M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5426/1476277003.py:95: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  gpsframe.replace('', np.nan, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Parse gps data marge with perception frame data\n",
    "Written for .UBX file generated by u-center for u-blox7 USB GPS\n",
    "\"\"\"\n",
    "# Empty dataframe for gps data\n",
    "gpsframe = pd.DataFrame()\n",
    "\n",
    "# Data lists\n",
    "times = []\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "altitudes = []\n",
    "altunits = []\n",
    "alttimes = []\n",
    "\n",
    "# Parse GPS messages from .ubx file\n",
    "for mode in (GET, SET, POLL):\n",
    "    msgcount = 0\n",
    "    ubr = None\n",
    "    \n",
    "    # Open file as U-Center .ubx file\n",
    "    if(gps_file.endswith('.ubx')):\n",
    "        print(\"Reading gps as U-Center output\")\n",
    "        with open(gps_file, \"rb\") as stream:\n",
    "            # Create reader\n",
    "            ubr = UBXReader(stream, quitonerror=ERR_IGNORE, parsing=True,msgmode=mode)\n",
    "\n",
    "        # Iterate through messages parsed by reader\n",
    "        for _, parsed in ubr:\n",
    "            # If message is valid\n",
    "            if parsed is not None:\n",
    "                msgcount += 1\n",
    "\n",
    "                # Grab latitude & longitude if present\n",
    "                if(hasattr(parsed, 'lat')):\n",
    "                    times.append(pd.to_datetime(date + str(' ' + parsed.time.strftime('%H:%M:%S'))))\n",
    "                    latitudes.append(parsed.lat)\n",
    "                    longitudes.append(parsed.lon)\n",
    "                # Grab altitude if present\n",
    "                if(hasattr(parsed,'alt')):\n",
    "                    altitudes.append(parsed.alt)\n",
    "                    altunits.append(parsed.altUnit)\n",
    "                    alttimes.append(pd.to_datetime(date + str(' ' + parsed.time.strftime('%H:%M:%S'))))\n",
    "            \n",
    "    # Open file as pygpsclient .log file\n",
    "    elif(gps_file.endswith('.log')):\n",
    "        print(\"Reading gps as pygpsclient binary output\")\n",
    "        with open(gps_file, 'rb') as stream:\n",
    "            # Create reader\n",
    "            ubr = UBXReader(stream, quitonerror=ERR_IGNORE, parsing=True, protfilter=UBX_PROTOCOL|NMEA_PROTOCOL|RTCM3_PROTOCOL)\n",
    "\n",
    "            # Iterate through messages parsed by reader\n",
    "            for _, parsed in ubr:\n",
    "                # If message is valid\n",
    "                if parsed is not None:\n",
    "                    msgcount += 1\n",
    "\n",
    "                    # Grab latitude & longitude if present\n",
    "                    if(hasattr(parsed, 'lat')):\n",
    "                        time = pd.to_datetime(parsed.time.strftime('%H:%M:%S')) - pd.DateOffset(hours=7)\n",
    "                        time = time.replace(year=date.year,month=date.month,day=date.day)\n",
    "                        times.append(time)\n",
    "                        latitudes.append(parsed.lat)\n",
    "                        longitudes.append(parsed.lon)\n",
    "                    # Grab altitude if present\n",
    "                    if(hasattr(parsed,'alt')):\n",
    "                        altitudes.append(parsed.alt)\n",
    "                        altunits.append(parsed.altUnit)\n",
    "                        time = pd.to_datetime(parsed.time.strftime('%H:%M:%S')) - pd.DateOffset(hours=7)\n",
    "                        time = time.replace(year=date.year,month=date.month,day=date.day)\n",
    "                        alttimes.append(time)\n",
    "\n",
    "    # Print number of messages parsed\n",
    "    print(f'\\n{msgcount} {(\"GET\",\"SET\",\"POLL\")[mode]} messages parsed\\n\\n')\n",
    "\n",
    "# Build gps dataframe\n",
    "gpsframe['Datetime'] = times\n",
    "gpsframe['Latitude'] = latitudes\n",
    "gpsframe['Longitude'] = longitudes\n",
    "gpsframe['Datetime'] = gpsframe['Datetime'].dt.tz_localize('America/Los_Angeles')\n",
    "\n",
    "# Build separate altitude dataframe since sampling rates are different\n",
    "altframe = pd.DataFrame()\n",
    "altframe['Altitude'] = altitudes\n",
    "altframe['Alt Unit'] = altunits\n",
    "altframe['Datetime'] = alttimes\n",
    "altframe['Datetime'] = altframe['Datetime'].dt.tz_localize('America/Los_Angeles')\n",
    "\n",
    "# Sort data by time\n",
    "gpsframe = gpsframe.sort_values(by='Datetime')\n",
    "altframe = altframe.sort_values(by='Datetime')\n",
    "\n",
    "# Merge GPS and nearest Altitude into GPS dataframe. 0 order hold altitude\n",
    "gpsframe = pd.merge_asof(gpsframe,altframe,on='Datetime',suffixes=('_gps','_alt'))\n",
    "gpsframe.replace('', np.nan, inplace = True)\n",
    "gpsframe = gpsframe.dropna(axis='rows')\n",
    "gpsframe.to_csv('gpsdata.csv')\n",
    "print(gpsframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping realsense IMU\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Read IMU from Realsense\n",
    "\"\"\"\n",
    "\n",
    "#TODO:\n",
    "#1. Change backend timestamp to global timestamp for accurate time delay correction\n",
    "\n",
    "if (IMU == IMUTypes.REALSENSE_IMU):\n",
    "    # open IMU file\n",
    "    rawimu = open(cam_frame_path + imu_file,'r')\n",
    "\n",
    "    # Empty lists for dataframe\n",
    "    gyro_data = []\n",
    "    accel_data = []\n",
    "\n",
    "    # Remove leading empty lines written by realsense tool\n",
    "    line = rawimu.readline()\n",
    "    line = rawimu.readline()    \n",
    "    line = rawimu.readline()\n",
    "\n",
    "    # Iterate through gyroscope data\n",
    "    while(line != '\\n'):\n",
    "        gyro_data.append(line.replace('\\n','').split(','))\n",
    "        line = rawimu.readline()\n",
    "        print(line)\n",
    "\n",
    "    # Remove leading empty lines\n",
    "    line = rawimu.readline()\n",
    "    line = rawimu.readline()\n",
    "\n",
    "    # Iterate through accelerometer data\n",
    "    while(line):\n",
    "        accel_data.append(line.replace('\\n','').split(','))\n",
    "        line = rawimu.readline()\n",
    "        print(line)\n",
    "\n",
    "    # Build pandas dataframe of IMU data\n",
    "    gyroframe = pd.DataFrame(gyro_data[1:],columns=gyro_data[0])\n",
    "    gyroframe['Backend Timestamp(ms)'] = gyroframe['Backend Timestamp(ms)'].astype(np.int64).apply(lambda x: pd.to_datetime(x,unit='ms'))\n",
    "    imuframe = pd.DataFrame(accel_data[1:],columns=accel_data[0])\n",
    "    imuframe['Backend Timestamp(ms)'] = imuframe['Backend Timestamp(ms)'].astype(np.int64).apply(lambda x: pd.to_datetime(x,unit='ms'))\n",
    "\n",
    "    # Merge by backend timestamp\n",
    "    imuframe = pd.merge_asof(imuframe,gyroframe,on='Backend Timestamp(ms)',suffixes=('_Accel','_Gyro'))\n",
    "    imuframe = imuframe.rename(columns={'Backend Timestamp(ms)':'Datetime'})\n",
    "    print(imuframe.head())\n",
    "else:\n",
    "    print('Skipping realsense IMU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cam frames: 13599\n",
      "Lidar frames: 4527\n",
      "Lidar frames with no matching camera: 2\n",
      "   lidar_id                           Timestart  \\\n",
      "0      2225 2024-09-09 19:21:49.466755093-07:00   \n",
      "1      2226 2024-09-09 19:21:49.566716380-07:00   \n",
      "2      2227 2024-09-09 19:21:49.666685136-07:00   \n",
      "3      2228 2024-09-09 19:21:49.766677044-07:00   \n",
      "4      2229 2024-09-09 19:21:49.866682603-07:00   \n",
      "\n",
      "                              Timeend  \\\n",
      "0 2024-09-09 19:21:49.566618911-07:00   \n",
      "1 2024-09-09 19:21:49.666578590-07:00   \n",
      "2 2024-09-09 19:21:49.766573072-07:00   \n",
      "3 2024-09-09 19:21:49.866579745-07:00   \n",
      "4 2024-09-09 19:21:49.966575696-07:00   \n",
      "\n",
      "                                          lidar_path  \\\n",
      "0  /home/khanj/Dev/PerceptionTools/DriveData/2024...   \n",
      "1  /home/khanj/Dev/PerceptionTools/DriveData/2024...   \n",
      "2  /home/khanj/Dev/PerceptionTools/DriveData/2024...   \n",
      "3  /home/khanj/Dev/PerceptionTools/DriveData/2024...   \n",
      "4  /home/khanj/Dev/PerceptionTools/DriveData/2024...   \n",
      "\n",
      "                             Datetime         Epoch  \\\n",
      "0 2024-09-09 19:21:49.516687002-07:00  1.725935e+12   \n",
      "1 2024-09-09 19:21:49.616647485-07:00  1.725935e+12   \n",
      "2 2024-09-09 19:21:49.716629104-07:00  1.725935e+12   \n",
      "3 2024-09-09 19:21:49.816628394-07:00  1.725935e+12   \n",
      "4 2024-09-09 19:21:49.916629149-07:00  1.725935e+12   \n",
      "\n",
      "                                         camera_path   Latitude   Longitude  \\\n",
      "0  /home/khanj/Dev/PerceptionTools/DriveData/2024...  48.775238 -122.457043   \n",
      "1  /home/khanj/Dev/PerceptionTools/DriveData/2024...  48.775238 -122.457043   \n",
      "2  /home/khanj/Dev/PerceptionTools/DriveData/2024...  48.775238 -122.457043   \n",
      "3  /home/khanj/Dev/PerceptionTools/DriveData/2024...  48.775238 -122.457043   \n",
      "4  /home/khanj/Dev/PerceptionTools/DriveData/2024...  48.775238 -122.457043   \n",
      "\n",
      "   Altitude Alt Unit     Acc_x     Acc_y     Acc_z    Gyro_x    Gyro_y  \\\n",
      "0      53.9        M -0.009033  0.016846  0.978760 -0.228882  0.160217   \n",
      "1      53.9        M  0.003906  0.016846  0.970947 -0.152588 -0.022888   \n",
      "2      53.9        M -0.013672  0.018066  0.979248  0.114441  0.312805   \n",
      "3      53.9        M  0.010254  0.012939  0.980225 -0.274658 -0.129700   \n",
      "4      53.9        M -0.015625  0.018311  0.979980  0.396729  0.572205   \n",
      "\n",
      "     Gyro_z  \n",
      "0 -0.183105  \n",
      "1  0.144958  \n",
      "2  0.053406  \n",
      "3 -0.061035  \n",
      "4  0.015259  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Merge closest lidar and camera frames to single dataframe\n",
    "Add GPS data\n",
    "Add IMU data\n",
    "\"\"\"\n",
    "\n",
    "# Print number of frames to be combined\n",
    "print(\"Cam frames: \" + str(len(cam_dataframe.index)))\n",
    "print(\"Lidar frames: \" + str(len(lidar_dataframe.index)))\n",
    "\n",
    "# Left hand SQL style join on lidar and camera frames\n",
    "frame_data = pd.DataFrame()\n",
    "frame_data = pd.merge_asof(lidar_dataframe.sort_values('Datetime'),cam_dataframe.sort_values('Datetime'),on='Datetime')\n",
    "\n",
    "# Print lone lidar frames\n",
    "print(\"Lidar frames with no matching camera: \" + str(frame_data.index.size - frame_data.dropna().index.size))\n",
    "frame_data = frame_data.dropna().reset_index(drop=True)\n",
    "\n",
    "# Calculate time between camera and lidar timestamps\n",
    "#frame_data['fused_frame_deltas'] = (frame_data['Datetime'] - frame_data['Datetime_y']).dt.total_seconds()\n",
    "\n",
    "# Match with closest gps\n",
    "frame_data = pd.merge_asof(frame_data,gpsframe,on='Datetime')\n",
    "\n",
    "# If we are saving IMU data from the realsense camera\n",
    "if(IMU == IMUTypes.REALSENSE_IMU):\n",
    "    # Match with closest IMU\n",
    "    frame_data = pd.merge_asof(frame_data,imuframe,on='Datetime')\n",
    "elif(IMU == IMUTypes.OUSTER_IMU):\n",
    "    frame_data = pd.merge_asof(frame_data,imu_frame,on='Datetime')\n",
    "\n",
    "# Save final dataframe to csv\n",
    "frame_data.to_csv(f'framedata_{date}.csv')\n",
    "print(frame_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/khanj/Dev/PerceptionTools/DriveData/2024-09-09/Export/pointcloud/timestamps.txt'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Move camera and lidar to final dataset directory and rename based on index\n",
    "\"\"\"\n",
    "\n",
    "# Create export directory if does not exist\n",
    "if (not os.path.exists(dest_path)):\n",
    "    os.makedirs(dest_path)\n",
    "if (not os.path.exists(lidar_dest)):\n",
    "    os.makedirs(lidar_dest)\n",
    "    os.makedirs(lidar_dest + 'data/')\n",
    "if (not os.path.exists(cam_dest)):\n",
    "    os.makedirs(cam_dest)\n",
    "    os.makedirs(cam_dest + 'data/')\n",
    "if (not os.path.exists(gps_dest)):\n",
    "    os.makedirs(gps_dest)\n",
    "if (not os.path.exists(gps_dest + 'data/')):\n",
    "    os.makedirs(gps_dest + 'data/')\n",
    "\n",
    "# Write frame timestamps to pointcloud/Data/\n",
    "timepath = f'{path}pointcloud/timestamps_start.txt'\n",
    "if(os.path.exists(timepath) == False):\n",
    "    with open(timepath, 'w') as f:\n",
    "        f.write(frame_data['Timestart'].to_string(header=False, index=False))\n",
    "\n",
    "timepath = f'{path}pointcloud/timestamps_end.txt'\n",
    "if(os.path.exists(timepath) == False):\n",
    "    with open(timepath, 'w') as f:\n",
    "        f.write(frame_data['Timeend'].to_string(header=False, index=False))\n",
    "\n",
    "timepath = f'{path}pointcloud/timestamps.txt'\n",
    "if(os.path.exists(timepath) == False):\n",
    "    with open(timepath,'w') as f:\n",
    "        f.write(frame_data['Datetime'].to_string(header=False, index=False))\n",
    "lidar_dataframe.head()\n",
    "\n",
    "# Write camera timestamps\n",
    "with open(f'{cam_dest}timestamps.txt','w') as f:\n",
    "    f.write(pd.to_datetime(frame_data['Epoch'], unit='ms').to_string(header=False, index=False))\n",
    "\n",
    "# Move matching frames to dataset directory based on index in matched dataframe\n",
    "for index, row in frame_data.iterrows():    \n",
    "    shutil.copy(row['lidar_path'], lidar_dest + 'data/' + '{index:010d}'.format(index = index) + '.' + extension)\n",
    "    shutil.copy(row['camera_path'], cam_dest + 'data/' + '{index:010d}'.format(index = index) + '.png')\n",
    "    #gpspath = gps_dest + 'data/' + f'{index:010d}'.format(index = index) + '.txt'\n",
    "    #f = open(gpspath,'x')\n",
    "    #f.write(str(row['Latitude']) + ' ' + str(row['Longitude']))\n",
    "    #f.close()\n",
    "\n",
    "# Copy lidar timestamps to export\n",
    "shutil.copy(f'{path}pointcloud/timestamps_end.txt', lidar_dest)\n",
    "shutil.copy(f'{path}pointcloud/timestamps_start.txt', lidar_dest)\n",
    "shutil.copy(f'{path}pointcloud/timestamps.txt', lidar_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Move IMU and GPS data to dataset directory\n",
    "'''\n",
    "\n",
    "motion_to_save = ['Latitude', 'Longitude', 'Altitude', 'Acc_x', 'Acc_y', 'Acc_z', 'Gyro_x', 'Gyro_y', 'Gyro_z']\n",
    "\n",
    "# Write navigation data format to readable file\n",
    "f = open(f'{gps_dest}dataformat.txt','w')\n",
    "for field in motion_to_save:\n",
    "    f.write(field + '\\n')\n",
    "f.close()\n",
    "\n",
    "# Write GPS data to Export/navigation\n",
    "for index, row in frame_data.iterrows():\n",
    "    with open(f'{gps_dest}/data/{index:010d}.txt','w') as f:\n",
    "        for field in motion_to_save:\n",
    "            f.write(str(row[field]) + '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
